{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "speech_RNN_CTC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codewithAshwani/Speech-Recognition-CTC-decoder/blob/main/speech_RNN_CTC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvEC6aZj0x3I"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy\n",
        "from pickle import dump\n",
        "from pickle import load\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dense, Activation, Bidirectional, Reshape\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D,TimeDistributed, LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V603m2ck2FpC"
      },
      "source": [
        "pickle_path = 'feature.pkl'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5XFfdG20x3L"
      },
      "source": [
        "# load data from data file\n",
        "def load_features(filename):\n",
        "    data = load(open(filename, 'rb'))\n",
        "\n",
        "    x = data[\"feauture_mfcc\"]\n",
        "    y = data[\"mapping\"]\n",
        "    return x,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOxTjWDR0x3R"
      },
      "source": [
        "x,y = load_features(pickle_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHVu4gP_0x3T",
        "outputId": "e3d229e1-0e16-44f6-f255-040b993eb0a5"
      },
      "source": [
        "max_length = max([len(label) for label in y])\n",
        "max_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoC64CrllMmL"
      },
      "source": [
        "# padding of words which are smaller than max_length, with character '<unk>'\n",
        "y_padded = []\n",
        "for i in range(len(y)):\n",
        "  val = list(y[i])\n",
        "  while len(val)<(max_length):\n",
        "    val.append('<unk>')\n",
        "  y_padded.append(val)\n",
        "# characters in label\n",
        "characters = set(char for label in y for char in label)\n",
        "# dictionary for tokenization of charaters \n",
        "char_to_num = dict(zip(sorted(characters) + ['<unk>'], list(range(len(characters) + 1))))\n",
        "num_to_char = {v:k for k,v in char_to_num.items()}\n",
        "# convert characters to integer token \n",
        "y2=[]\n",
        "for label in y_padded:\n",
        "  y2.append([char_to_num[i] for i in label])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-XTSRPQvgXB",
        "outputId": "b94e79c6-2dd3-4b03-a09f-5278366806f5"
      },
      "source": [
        "len(characters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TqMXCk9Fud-D",
        "outputId": "993914fe-0983-492e-8b7c-efd8ee85c6c8"
      },
      "source": [
        "''.join([num_to_char[i] for i in y2[-1]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'zero<unk>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGuZ1nM80x3V",
        "outputId": "e1804605-f3b8-433a-9c21-992177a11741"
      },
      "source": [
        "x = np.asarray(x)\n",
        "x = x.reshape(-1,x.shape[1],x.shape[2],1)\n",
        "width = x.shape[1]\n",
        "height = x.shape[2]\n",
        "width,height"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb10nGHb0x3W"
      },
      "source": [
        "# Split the data\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x, np.asarray(y2), test_size=0.01, shuffle= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ye9emHk0x3X",
        "outputId": "41ba8983-c33c-4573-a3eb-6ecdb67a90d8"
      },
      "source": [
        "x_train.shape, y_train.shape, x_valid.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2970, 55, 13, 1), (2970, 5), (30, 55, 13, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3BFLMiA0x3Y"
      },
      "source": [
        "BUFFER_SIZE = x_train.shape[0]\n",
        "BATCH_SIZE = 16\n",
        "steps_per_epoch = x_train.shape[0]//BATCH_SIZE\n",
        "units = 128\n",
        "dropout = 0.0\n",
        "beam_widt = 3\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N9yLfH70x3Z"
      },
      "source": [
        "BUFFER_SIZE_TEST = x_valid.shape[0]\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((x_valid, y_valid)).shuffle(BUFFER_SIZE_TEST)\n",
        "dataset_test = dataset_test.batch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej51mz36nBmK"
      },
      "source": [
        "# Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYUe4p4Z0x3Z"
      },
      "source": [
        "class encoder(tf.keras.Model):\n",
        "    def __init__(self, units, batch_size, characters, dropout, img_width, img_height):\n",
        "        super(encoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.units = units\n",
        "        self.characters = characters\n",
        "        self.dropout = dropout\n",
        "        self.img_width = img_width\n",
        "        self.img_height = img_height\n",
        "\n",
        "        self.Conv2D1 = Conv2D(32,(3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\", name=\"Conv1\")\n",
        "        self.MaxPooling2D1 = MaxPooling2D((2, 2), name=\"pool1\")\n",
        "        self.Conv2D2 = Conv2D(64,(3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\", name=\"Conv2\")\n",
        "        self.MaxPooling2D2 = MaxPooling2D((2, 2), name=\"pool2\")\n",
        "\n",
        "        self.Reshape= Reshape(target_shape=((self.img_width // 4), (self.img_height // 4) * 64), name=\"reshape\")\n",
        "        self.Dense=Dense(64, activation=\"relu\", name=\"dense1\")\n",
        "        self.BidiLSTM1=Bidirectional(LSTM(units, return_sequences=True, dropout=self.dropout))\n",
        "        self.BidiLSTM2=Bidirectional(LSTM(units, return_sequences=True, dropout=self.dropout))\n",
        "        self.Dense1 = TimeDistributed(Dense(len(self.characters)+1, name=\"dense2\"))\n",
        "        self.Dense2 = TimeDistributed(Activation('softmax'), name='softmax')\n",
        "    def call(self, x):\n",
        "        x = self.Conv2D1(x)\n",
        "        x = self.MaxPooling2D1(x)\n",
        "        x = self.Conv2D2(x)\n",
        "        x = self.MaxPooling2D2(x)\n",
        "        x = self.Reshape(x)\n",
        "        x = self.Dense(x)\n",
        "        x = self.BidiLSTM1(x)\n",
        "        x = self.BidiLSTM2(x)\n",
        "        x = self.Dense1(x)\n",
        "        output = self.Dense2(x)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NboPlm4n0x3a"
      },
      "source": [
        "encoder = encoder(units, BATCH_SIZE, characters, dropout, width, height)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJQ4S-yQnGJ_"
      },
      "source": [
        "**Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPnDWVJV0x3a"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "class CTCLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.loss_func = tf.keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "\n",
        "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "        label_length = tf.cast(tf.fill([batch_len, 1], label_length), dtype=\"int64\")\n",
        "        input_length = tf.cast(tf.fill([batch_len, 1], input_length), dtype=\"int64\")\n",
        "\n",
        "\n",
        "\n",
        "        loss = self.loss_func(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CZWr6-c0x3b"
      },
      "source": [
        "CTC_Layer = CTCLayer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkjpSy8a0x3c"
      },
      "source": [
        "@tf.function\n",
        "def train_step(x_batch_train, y_batch_train):\n",
        "    loss = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        output = encoder(x_batch_train) \n",
        "        output = CTC_Layer(y_batch_train, output)\n",
        "        loss += tf.math.reduce_mean(CTC_Layer.losses)\n",
        "\n",
        "    batch_loss = (loss / y_batch_train.shape[1])   \n",
        "    variables = encoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rILi7Jsl0x3d",
        "outputId": "3b32d9f5-f16e-4997-ce8b-1320a428697d"
      },
      "source": [
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    total_loss = 0\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(dataset):\n",
        "        batch_loss = train_step(x_batch_train, y_batch_train)\n",
        "        total_loss += batch_loss\n",
        "    print(f'Epoch {epoch+1} Loss {total_loss:.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 415.7357\n",
            "Time taken for 1 epoch 9.26 sec\n",
            "\n",
            "Epoch 2 Loss 260.5452\n",
            "Time taken for 1 epoch 3.21 sec\n",
            "\n",
            "Epoch 3 Loss 153.4986\n",
            "Time taken for 1 epoch 3.25 sec\n",
            "\n",
            "Epoch 4 Loss 95.5731\n",
            "Time taken for 1 epoch 3.28 sec\n",
            "\n",
            "Epoch 5 Loss 64.1474\n",
            "Time taken for 1 epoch 3.19 sec\n",
            "\n",
            "Epoch 6 Loss 44.8002\n",
            "Time taken for 1 epoch 3.09 sec\n",
            "\n",
            "Epoch 7 Loss 33.5921\n",
            "Time taken for 1 epoch 3.09 sec\n",
            "\n",
            "Epoch 8 Loss 24.6286\n",
            "Time taken for 1 epoch 3.07 sec\n",
            "\n",
            "Epoch 9 Loss 20.2038\n",
            "Time taken for 1 epoch 3.07 sec\n",
            "\n",
            "Epoch 10 Loss 17.0169\n",
            "Time taken for 1 epoch 3.08 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAKYwgxV0x3e"
      },
      "source": [
        "def greedy_predictions(pred):\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    # Use greedy search.\n",
        "    results = tf.keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
        "        :, :max_length\n",
        "    ]\n",
        "    # Iterate over the results and get back the text\n",
        "    resultn = np.array([i for i in tf.reshape(results, [max_length]).numpy() if i!=-1]) \n",
        "    output_text = ''.join([num_to_char[i] for i in resultn])\n",
        "    return output_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nyN9WMJ0x3f",
        "outputId": "bb08ba26-ade7-488e-ab8d-61a9dd4e564a"
      },
      "source": [
        "for i, (x_batch_test, y_batch_test) in enumerate(dataset_test):\n",
        "    preds = encoder(x_batch_test)\n",
        "    pred_texts = greedy_predictions(preds)\n",
        "    y_batch = np.array([i for i in tf.reshape(y_batch_test, [max_length]).numpy() if i != (len(characters))]) \n",
        "    label_true = ''.join([num_to_char[i] for i in y_batch])\n",
        "    print(f\"Actual :  {label_true},    Predicted :  {pred_texts}\")   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual :  nine,    Predicted :  nine\n",
            "Actual :  eight,    Predicted :  eight\n",
            "Actual :  two,    Predicted :  tie\n",
            "Actual :  nine,    Predicted :  nine\n",
            "Actual :  four,    Predicted :  four\n",
            "Actual :  eight,    Predicted :  eight\n",
            "Actual :  five,    Predicted :  five\n",
            "Actual :  zero,    Predicted :  zero\n",
            "Actual :  eight,    Predicted :  eight\n",
            "Actual :  seven,    Predicted :  nve\n",
            "Actual :  zero,    Predicted :  zero\n",
            "Actual :  eight,    Predicted :  eight\n",
            "Actual :  two,    Predicted :  two\n",
            "Actual :  zero,    Predicted :  zero\n",
            "Actual :  one,    Predicted :  one\n",
            "Actual :  zero,    Predicted :  zero\n",
            "Actual :  four,    Predicted :  four\n",
            "Actual :  seven,    Predicted :  seven\n",
            "Actual :  nine,    Predicted :  nine\n",
            "Actual :  three,    Predicted :  thre\n",
            "Actual :  four,    Predicted :  four\n",
            "Actual :  three,    Predicted :  three\n",
            "Actual :  six,    Predicted :  six\n",
            "Actual :  six,    Predicted :  six\n",
            "Actual :  zero,    Predicted :  zero\n",
            "Actual :  three,    Predicted :  thre\n",
            "Actual :  seven,    Predicted :  seven\n",
            "Actual :  zero,    Predicted :  zero\n",
            "Actual :  zero,    Predicted :  zero\n",
            "Actual :  nine,    Predicted :  nine\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IWmUYSE0x3g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}